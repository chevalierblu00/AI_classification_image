{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Un dataset préfait (FGVCAircraft)\n",
    "\n",
    "training_dataset = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FGVCAircraft\n",
      "    Number of datapoints: 3334\n",
      "    Root location: data\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Image shape: torch.Size([3, 28, 28])\n",
      "Label: 0\n",
      "Nombre total de labels: 3334\n",
      "Labels uniques: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n"
     ]
    }
   ],
   "source": [
    "# Afficher des informations sur le dataset\n",
    "print(training_dataset)\n",
    "\n",
    "# Accéder aux données et aux labels\n",
    "image, label = training_dataset[0]  # Exemple du premier élément du dataset\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Parcourir toutes les cibles (labels)\n",
    "all_labels = [training_dataset[i][1] for i in range(len(training_dataset))]\n",
    "print(f\"Nombre total de labels: {len(all_labels)}\")\n",
    "print(f\"Labels uniques: {set(all_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.0494049..2.4308496].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7906162..1.9602616].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.6475817..2.3262744].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.5185376..1.8905448].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.5980392..2.6051416].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.3472902..1.6291069].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8267832..2.4308496].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8610327..2.169412].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7411594..2.3262744].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer une figure pour afficher des exemples d'images\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # Sélectionner un index aléatoire\n",
    "    sample_idx = torch.randint(len(training_dataset), size=(1,)).item()\n",
    "    \n",
    "    # Charger une image et son label\n",
    "    img, label = training_dataset[sample_idx]\n",
    "    \n",
    "    # Ajouter un sous-graphique\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"Label: {label}\")  # Afficher le label\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Afficher l'image\n",
    "    # img est un tenseur (C, H, W), on doit le transposer en (H, W, C) pour matplotlib\n",
    "    plt.imshow(img.permute(1, 2, 0))  # Transposer pour matplotlib\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X (images) : torch.Size([64, 3, 28, 28])\n",
      "Shape de y (labels) : torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((28, 28)),  # Redimensionner à 28x28\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # Normalisation ImageNet\n",
    "])\n",
    "\n",
    "training_dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# Définir les DataLoaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Tester le DataLoader\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape de X (images) : {X.shape}\")\n",
    "    print(f\"Shape de y (labels) : {y.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims, input_shape):\n",
    "        \"\"\"\n",
    "        Initialise un MLP pour des dimensions données.\n",
    "        :param dims: Liste des dimensions des couches [input_dim, hidden1, hidden2, ..., output_dim]\n",
    "        :param input_shape: Tuple représentant la taille d'entrée (C, H, W)\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Aplatir les images\n",
    "        input_dim = input_shape[0] * input_shape[1] * input_shape[2]  # C * H * W\n",
    "\n",
    "        # Créer les couches entièrement connectées\n",
    "        self.fcs = nn.ModuleList(\n",
    "            [nn.Linear(input_dim if i == 0 else dims[i], dims[i+1]) for i in range(len(dims)-1)]\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Aplatir l'entrée\n",
    "        for layer in self.fcs:\n",
    "            x = layer(x)\n",
    "            x = self.act(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accélérateur cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Accélérateur {device}\")\n",
    "\n",
    "input_shape = (3, 28, 28)  # Taille corrigée des images RGB\n",
    "input_dim = input_shape[0] * input_shape[1] * input_shape[2]  # 3 x 28 x 28 = 2352\n",
    "output_dim = 100  # Nombre de classes pour FGVCAircraft\n",
    "\n",
    "model = MLP([input_dim, 128, 128, output_dim], input_shape).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fcs): ModuleList(\n",
       "    (0): Linear(in_features=2352, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       "  (act): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # Expect raw logits (!= probabilities)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de boucle d'entraînement (mise à jour pour le GPU)\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Envoyer les données sur le GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Prédiction\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Affichage périodique des pertes\n",
    "        if batch % 100 == 0:\n",
    "            loss_value = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"Loss: {loss_value:>7f} [{current:>5d}/{len(dataloader.dataset)}]\")\n",
    "\n",
    "# Fonction de boucle de test (mise à jour pour le GPU)\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # Envoyer les données sur le GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Prédiction\n",
    "            y_pred = model(X)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test loss: {test_loss:>8f} | Test accuracy: {(correct * 100):>0.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ------------------------\n",
      "Loss: 3.682770 [    0/3334]\n",
      "Test loss: 4.605170 | Test accuracy: 0.99%\n",
      "Epoch 2 ------------------------\n",
      "Loss: 4.605170 [    0/3334]\n",
      "Test loss: 4.605170 | Test accuracy: 0.99%\n",
      "Epoch 3 ------------------------\n",
      "Loss: 4.605170 [    0/3334]\n",
      "Test loss: 4.605170 | Test accuracy: 0.99%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Boucle principale\n",
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} ------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test_loop(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Un dataset préfait (FGVCAircraft)\n",
    "\n",
    "training_dataset = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (par canal): tensor([0.4787, 0.5102, 0.5343])\n",
      "Standard deviation (par canal): tensor([0.1956, 0.1943, 0.2160])\n"
     ]
    }
   ],
   "source": [
    "#mean, variance des images\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# Initialiser mean et std comme des tenseurs de dimension (3,) pour chaque canal (R, G, B)\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "\n",
    "# Combiner les datasets d'entraînement et de test\n",
    "combined_data = ConcatDataset([training_dataset, test_dataset])\n",
    "\n",
    "# Nombre total d'images\n",
    "num_images = len(combined_data)\n",
    "\n",
    "for image, label in combined_data:\n",
    "    # Vérifier que l'image est bien en format (C, H, W)\n",
    "    if image.ndim == 3:\n",
    "        mean += image.mean(dim=(1, 2))  # Moyenne par canal\n",
    "        std += image.std(dim=(1, 2))   # Écart-type par canal\n",
    "    else:\n",
    "        raise ValueError(f\"L'image doit être en format (C, H, W), mais elle a la forme {image.shape}\")\n",
    "\n",
    "# Calculer la moyenne et l'écart-type finaux\n",
    "mean /= num_images\n",
    "std /= num_images\n",
    "\n",
    "print(f\"Mean (par canal): {mean}\")\n",
    "print(f\"Standard deviation (par canal): {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer Un dataset préfait (FGVCAircraft)\n",
    "\n",
    "training_dataset_V2 = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    ")\n",
    "\n",
    "test_dataset_V2 = datasets.FGVCAircraft(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (R, G, B): tensor([ 1.6492e-06,  2.5082e-06, -5.5617e-06])\n",
      "Standard Deviation (R, G, B): tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "#mean, variance des images\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# Initialisation des variables pour la moyenne et la variance\n",
    "mean = torch.zeros(3)  # Une valeur pour chaque canal (R, G, B)\n",
    "std = torch.zeros(3)\n",
    "\n",
    "# Combiner les datasets d'entraînement et de test\n",
    "combined_data = ConcatDataset([training_dataset_V2, test_dataset_V2])\n",
    "\n",
    "# Calculer la moyenne et la variance pour chaque canal\n",
    "for image, label in combined_data:\n",
    "    # Assurez-vous que l'image est sous forme de tenseur avec les dimensions (C, H, W)\n",
    "    if len(image.shape) == 3:  # (C, H, W)\n",
    "        for c in range(3):  # Parcourir chaque canal\n",
    "            mean[c] += image[c, :, :].mean()\n",
    "            std[c] += image[c, :, :].std()\n",
    "    else:\n",
    "        raise ValueError(\"Les images doivent être au format (C, H, W).\")\n",
    "\n",
    "# Diviser par le nombre total d'images pour obtenir la moyenne\n",
    "mean /= len(combined_data)\n",
    "std /= len(combined_data)\n",
    "\n",
    "print(f\"Mean (R, G, B): {mean}\")\n",
    "print(f\"Standard Deviation (R, G, B): {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8588, 0.8549, 0.8588,  ..., 0.8745, 0.8706, 0.8627],\n",
       "          [0.8510, 0.8627, 0.8706,  ..., 0.8588, 0.8627, 0.8706],\n",
       "          [0.8510, 0.8667, 0.8706,  ..., 0.8667, 0.8745, 0.8784],\n",
       "          ...,\n",
       "          [0.0000, 0.2275, 0.3961,  ..., 0.0118, 0.0039, 0.0078],\n",
       "          [0.0000, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n",
       "          [0.0157, 0.0157, 0.0235,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8588, 0.8549, 0.8588,  ..., 0.8745, 0.8706, 0.8627],\n",
       "          [0.8510, 0.8627, 0.8706,  ..., 0.8588, 0.8627, 0.8706],\n",
       "          [0.8510, 0.8667, 0.8706,  ..., 0.8667, 0.8745, 0.8784],\n",
       "          ...,\n",
       "          [0.0353, 0.2745, 0.4510,  ..., 0.0039, 0.0000, 0.0000],\n",
       "          [0.0078, 0.0078, 0.0078,  ..., 0.0000, 0.0000, 0.0039],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8588, 0.8549, 0.8588,  ..., 0.8745, 0.8706, 0.8627],\n",
       "          [0.8510, 0.8627, 0.8706,  ..., 0.8588, 0.8627, 0.8706],\n",
       "          [0.8510, 0.8667, 0.8706,  ..., 0.8667, 0.8745, 0.8784],\n",
       "          ...,\n",
       "          [0.0314, 0.3216, 0.5020,  ..., 0.0078, 0.0000, 0.0039],\n",
       "          [0.0000, 0.0157, 0.0039,  ..., 0.0000, 0.0000, 0.0039],\n",
       "          [0.0039, 0.0157, 0.0157,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.9430,  1.9229,  1.9430,  ...,  2.0232,  2.0031,  1.9630],\n",
       "          [ 1.9029,  1.9630,  2.0031,  ...,  1.9430,  1.9630,  2.0031],\n",
       "          [ 1.9029,  1.9831,  2.0031,  ...,  1.9831,  2.0232,  2.0432],\n",
       "          ...,\n",
       "          [-2.4470, -1.2844, -0.4224,  ..., -2.3869, -2.4270, -2.4069],\n",
       "          [-2.4470, -2.4270, -2.4470,  ..., -2.4470, -2.4470, -2.4270],\n",
       "          [-2.3668, -2.3668, -2.3267,  ..., -2.4470, -2.4470, -2.4470]],\n",
       " \n",
       "         [[ 1.7944,  1.7742,  1.7944,  ...,  1.8751,  1.8549,  1.8146],\n",
       "          [ 1.7540,  1.8146,  1.8549,  ...,  1.7944,  1.8146,  1.8549],\n",
       "          [ 1.7540,  1.8347,  1.8549,  ...,  1.8347,  1.8751,  1.8953],\n",
       "          ...,\n",
       "          [-2.4442, -1.2130, -0.3048,  ..., -2.6057, -2.6259, -2.6259],\n",
       "          [-2.5855, -2.5855, -2.5855,  ..., -2.6259, -2.6259, -2.6057],\n",
       "          [-2.6259, -2.6259, -2.6259,  ..., -2.6259, -2.6259, -2.6259]],\n",
       " \n",
       "         [[ 1.5022,  1.4841,  1.5022,  ...,  1.5749,  1.5567,  1.5204],\n",
       "          [ 1.4659,  1.5204,  1.5567,  ...,  1.5022,  1.5204,  1.5567],\n",
       "          [ 1.4659,  1.5386,  1.5567,  ...,  1.5386,  1.5749,  1.5930],\n",
       "          ...,\n",
       "          [-2.3287, -0.9851, -0.1499,  ..., -2.4376, -2.4739, -2.4558],\n",
       "          [-2.4739, -2.4013, -2.4558,  ..., -2.4739, -2.4739, -2.4558],\n",
       "          [-2.4558, -2.4013, -2.4013,  ..., -2.4739, -2.4739, -2.4739]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_V2[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X (images): torch.Size([64, 3, 28, 28])\n",
      "Shape de y (labels): torch.Size([64])\n",
      "Labels uniques dans le batch: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Définir le batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Ajouter une transformation pour redimensionner les images\n",
    "transform = T.Compose([\n",
    "    T.Resize((28, 28)),  # Redimensionner à 28x28\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # Normalisation ImageNet\n",
    "])\n",
    "\n",
    "# Appliquer la transformation aux datasets\n",
    "training_dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# Créer les DataLoaders pour entraînement et test\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Parcourir un batch de test\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape de X (images): {X.shape}\")  # Dimensions des images dans le batch\n",
    "    print(f\"Shape de y (labels): {y.shape}\")  # Dimensions des labels dans le batch\n",
    "    print(f\"Labels uniques dans le batch: {y.unique()}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ------------------------\n",
      "Loss: 4.197552 [    0/3334]\n",
      "Test loss: 4.483652 | Test accuracy: 5.73%\n",
      "Epoch 2 ------------------------\n",
      "Loss: 4.306851 [    0/3334]\n",
      "Test loss: 4.462152 | Test accuracy: 6.69%\n",
      "Epoch 3 ------------------------\n",
      "Loss: 4.089507 [    0/3334]\n",
      "Test loss: 4.443366 | Test accuracy: 7.14%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} ------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test_loop(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accélérateur cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Accélérateur {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Using cached grpcio-1.70.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from tensorboard) (24.2)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from tensorboard) (1.17.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached grpcio-1.70.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.70.0 markdown-3.7 protobuf-5.29.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
      "Epoch 1/3\n",
      "Train Loss: 4.1013, Train Accuracy: 15.60%\n",
      "Test Loss: 4.4589, Test Accuracy: 6.84%\n",
      "------------------------------\n",
      "Epoch 2/3\n",
      "Train Loss: 4.0247, Train Accuracy: 17.70%\n",
      "Test Loss: 4.4557, Test Accuracy: 7.47%\n",
      "------------------------------\n",
      "Epoch 3/3\n",
      "Train Loss: 3.9240, Train Accuracy: 20.19%\n",
      "Test Loss: 4.4508, Test Accuracy: 7.29%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Install tensorboard package\n",
    "%pip install tensorboard\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/fgvcaircraft_experiment')\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        epoch_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), correct / len(dataloader.dataset) * 100\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    return test_loss / len(dataloader), correct / len(dataloader.dataset) * 100\n",
    "\n",
    "def train_and_test(dataloader_train, dataloader_test, model, loss_fn, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        # Train the model\n",
    "        train_loss, train_accuracy = train_loop(dataloader_train, model, loss_fn, optimizer)\n",
    "        writer.add_scalars('Loss', {'train': train_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'train': train_accuracy}, epoch)\n",
    "\n",
    "        # Test the model\n",
    "        test_loss, test_accuracy = test_loop(dataloader_test, model, loss_fn)\n",
    "        writer.add_scalars('Loss', {'test': test_loss}, epoch)\n",
    "        writer.add_scalars('Accuracy', {'test': test_accuracy}, epoch)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print('-' * 30)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# Lancer l'entraînement et le test\n",
    "train_and_test(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Réduit les dimensions de moitié\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Réduit encore les dimensions de moitié\n",
    "        )\n",
    "        \n",
    "        # Calcul dynamique de la taille de sortie\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 28, 28)  # Entrée avec taille 28x28\n",
    "            conv_output = self.conv_stack(dummy_input)\n",
    "            conv_output_size = int(torch.prod(torch.tensor(conv_output.shape[1:])))\n",
    "        \n",
    "        # Définition de la pile fully-connected\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_output_size, 512),  # Taille calculée dynamiquement\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(num_classes=output_dim).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(cnn.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 4.6082, Train Accuracy: 0.93%\n",
      "Test Loss: 4.6030, Test Accuracy: 0.96%\n",
      "------------------------------\n",
      "Epoch 2/3\n",
      "Train Loss: 4.5518, Train Accuracy: 1.29%\n",
      "Test Loss: 4.4933, Test Accuracy: 1.83%\n",
      "------------------------------\n",
      "Epoch 3/3\n",
      "Train Loss: 4.4666, Train Accuracy: 2.61%\n",
      "Test Loss: 4.4528, Test Accuracy: 3.12%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "wr  = SummaryWriter('runs/fgvcaircraft_experiment_2')\n",
    "train_and_test(train_dataloader, test_dataloader, cnn, loss_fn, optimizer, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnx) (2.2.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnx) (5.29.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnxscript in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnxscript) (2.2.2)\n",
      "Requirement already satisfied: onnx>=1.16 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnxscript) (1.17.0)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnxscript) (4.12.2)\n",
      "Requirement already satisfied: ml_dtypes in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnxscript) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnxscript) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mgasp\\onedrive\\bureau\\ia\\.venv\\lib\\site-packages (from onnx>=1.16->onnxscript) (5.29.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install onnx\n",
    "%pip install onnxscript\n",
    "\n",
    "cnn.to('cpu')\n",
    "torch_input = torch.randn(1, 3, 28, 28)  # Change to 3 channels\n",
    "onnx_program = torch.onnx.export(cnn, torch_input, \"model.onnx\", verbose=True, input_names=['input'], output_names=['output'], opset_version=11, export_params=True,do_constant_folding=True,dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
